{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), kernel_initializer='TruncatedNormal',input_shape = (32, 32, 3), activation = 'selu'))\n",
    "classifier.add(Conv2D(32, (3, 3),kernel_initializer='TruncatedNormal', activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3),kernel_initializer='TruncatedNormal', activation = 'selu'))\n",
    "classifier.add(Conv2D(32, (3, 3),kernel_initializer='TruncatedNormal', activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3),kernel_initializer='TruncatedNormal', activation = 'selu'))\n",
    "classifier.add(Conv2D(32, (3, 3),kernel_initializer='TruncatedNormal', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.add(Dense(units = 100,kernel_initializer='TruncatedNormal', activation = 'relu'))\n",
    "classifier.add(Dense(units = 30,kernel_initializer='TruncatedNormal', activation = 'relu'))\n",
    "classifier.add(Dense(units = 6,kernel_initializer='TruncatedNormal', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True,rotation_range=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='E:\\I neuron DLNLPCV\\DL DATASETS\\intel image classification\\seg_train\\seg_train'\n",
    "test_path='E:\\I neuron DLNLPCV\\DL DATASETS\\intel image classification\\seg_test\\seg_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "target_size = (32, 32),batch_size = 32,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "target_size = (32, 32), batch_size = 32,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 1.0853 - accuracy: 0.5641 - val_loss: 0.8733 - val_accuracy: 0.6081\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 547s 547ms/step - loss: 0.8727 - accuracy: 0.6672 - val_loss: 0.8630 - val_accuracy: 0.6823\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 367s 367ms/step - loss: 0.7676 - accuracy: 0.7158 - val_loss: 0.3893 - val_accuracy: 0.7327\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 418s 418ms/step - loss: 0.6951 - accuracy: 0.7458 - val_loss: 0.4515 - val_accuracy: 0.7541\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 376s 376ms/step - loss: 0.6449 - accuracy: 0.7638 - val_loss: 0.5923 - val_accuracy: 0.7798\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 368s 368ms/step - loss: 0.6052 - accuracy: 0.7819 - val_loss: 0.5459 - val_accuracy: 0.7877\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 371s 371ms/step - loss: 0.5620 - accuracy: 0.7984 - val_loss: 0.6916 - val_accuracy: 0.7719\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 301s 301ms/step - loss: 0.5353 - accuracy: 0.8054 - val_loss: 0.5312 - val_accuracy: 0.7771\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 317s 317ms/step - loss: 0.5064 - accuracy: 0.8171 - val_loss: 0.8445 - val_accuracy: 0.7577\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 402s 402ms/step - loss: 0.4890 - accuracy: 0.8209 - val_loss: 0.4999 - val_accuracy: 0.7817\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.4576 - accuracy: 0.8351 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 377s 377ms/step - loss: 0.4374 - accuracy: 0.8398 - val_loss: 0.3071 - val_accuracy: 0.7677\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 365s 365ms/step - loss: 0.4273 - accuracy: 0.8440 - val_loss: 0.4712 - val_accuracy: 0.7861\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 266s 266ms/step - loss: 0.4113 - accuracy: 0.8493 - val_loss: 0.5518 - val_accuracy: 0.7803\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 315s 315ms/step - loss: 0.3946 - accuracy: 0.8552 - val_loss: 1.1999 - val_accuracy: 0.7834\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 0.3832 - accuracy: 0.8592 - val_loss: 1.1766 - val_accuracy: 0.7953\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 373s 373ms/step - loss: 0.3748 - accuracy: 0.8623 - val_loss: 0.3606 - val_accuracy: 0.7871\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 440s 440ms/step - loss: 0.3519 - accuracy: 0.8699 - val_loss: 0.6986 - val_accuracy: 0.7922\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 291s 291ms/step - loss: 0.3393 - accuracy: 0.8762 - val_loss: 0.6457 - val_accuracy: 0.7793\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 312s 312ms/step - loss: 0.3395 - accuracy: 0.8759 - val_loss: 0.6426 - val_accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(training_set,steps_per_epoch = 1000,epochs = 20,validation_data = test_set,validation_steps = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.8732640743255615,\n",
       "  0.8629936575889587,\n",
       "  0.3892638087272644,\n",
       "  0.45153719186782837,\n",
       "  0.5922651290893555,\n",
       "  0.5458935499191284,\n",
       "  0.6915892362594604,\n",
       "  0.5311799049377441,\n",
       "  0.8444637060165405,\n",
       "  0.49994945526123047,\n",
       "  0.5136604309082031,\n",
       "  0.30706027150154114,\n",
       "  0.47123095393180847,\n",
       "  0.5518450736999512,\n",
       "  1.1999049186706543,\n",
       "  1.17661714553833,\n",
       "  0.36055755615234375,\n",
       "  0.6986380815505981,\n",
       "  0.6457277536392212,\n",
       "  0.6425718069076538],\n",
       " 'val_accuracy': [0.6080827116966248,\n",
       "  0.682330846786499,\n",
       "  0.7327067852020264,\n",
       "  0.75407475233078,\n",
       "  0.7797619104385376,\n",
       "  0.7877193093299866,\n",
       "  0.7719408273696899,\n",
       "  0.7770676612854004,\n",
       "  0.7577067613601685,\n",
       "  0.7817201614379883,\n",
       "  0.7708020210266113,\n",
       "  0.7677318453788757,\n",
       "  0.7861083149909973,\n",
       "  0.7802631855010986,\n",
       "  0.7833960056304932,\n",
       "  0.7952607870101929,\n",
       "  0.7870927453041077,\n",
       "  0.7922306060791016,\n",
       "  0.7792752981185913,\n",
       "  0.7934837341308594],\n",
       " 'loss': [1.0853527768165616,\n",
       "  0.8725288203962381,\n",
       "  0.7676218011852619,\n",
       "  0.6951554648333015,\n",
       "  0.6448057961563853,\n",
       "  0.6048318788318776,\n",
       "  0.5618981192880945,\n",
       "  0.5352377458018291,\n",
       "  0.5065120054259947,\n",
       "  0.4892009633847788,\n",
       "  0.4575184827213008,\n",
       "  0.4374121405098941,\n",
       "  0.4273311548502681,\n",
       "  0.4111558450345147,\n",
       "  0.39469043987870855,\n",
       "  0.38308795194489836,\n",
       "  0.3749161353825322,\n",
       "  0.3519926060918306,\n",
       "  0.3392059279132362,\n",
       "  0.3394254462875345],\n",
       " 'accuracy': [0.56405604,\n",
       "  0.66721946,\n",
       "  0.7158138,\n",
       "  0.74577755,\n",
       "  0.7638246,\n",
       "  0.78193253,\n",
       "  0.7984174,\n",
       "  0.80540085,\n",
       "  0.8171075,\n",
       "  0.8209212,\n",
       "  0.8350744,\n",
       "  0.83978975,\n",
       "  0.8439572,\n",
       "  0.8493369,\n",
       "  0.8551858,\n",
       "  0.8591893,\n",
       "  0.862317,\n",
       "  0.8698605,\n",
       "  0.8762438,\n",
       "  0.8758832]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"Intel_Image.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
